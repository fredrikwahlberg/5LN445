{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some examples of early encryption\n",
    "First, we need some reference data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package gutenberg to\n",
      "[nltk_data]     /home/fredrik/nltk_data...\n",
      "[nltk_data]   Package gutenberg is already up-to-date!\n",
      "Created 4 models\n",
      "['[', 'Emma', 'by', 'Jane', 'Austen', '1816', ']', ...] \t 1-gram model with 7811 unique keys\n",
      "['[', 'Persuasion', 'by', 'Jane', 'Austen', '1818', ...] \t 1-gram model with 6132 unique keys\n",
      "['[', 'Sense', 'and', 'Sensibility', 'by', 'Jane', ...] \t 1-gram model with 6833 unique keys\n",
      "['[', 'The', 'King', 'James', 'Bible', ']', 'The', ...] \t 1-gram model with 13769 unique keys\n",
      "[emma by jane austen 1816]\n",
      "\n",
      "volume i\n",
      "\n",
      "chapter i\n",
      "\n",
      "\n",
      "emma woodhouse, handsome, clever, and rich, with a comfortable home\n",
      "and happy disposition, seemed to unite some of the best blessings\n",
      "of existence; and had lived nearly twenty-one years in the world\n",
      "with very little to distress or vex her.\n",
      "\n",
      "she was the youngest of the two daughters of a most affectionate,\n",
      "indulgent father; and had, in consequence of her sister's marriage,\n",
      "been mistress of his house from a very early period.  her mother\n",
      "had died too long ago for her to have more than an indistinct\n",
      "remembrance of her caresses; and her place had been supplied\n",
      "by an excellent woman as governess, who had fallen little short\n",
      "of a mother in affection.\n",
      "\n",
      "sixteen years had miss taylor been in mr. woodhouse's family,\n",
      "less as a governess than a friend,\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import gutenberg\n",
    "nltk.download('gutenberg')\n",
    "from ngram import NGramModel\n",
    "from multiprocessing import Pool\n",
    "data = [gutenberg.words(book) for book in nltk.corpus.gutenberg.fileids()]\n",
    "def f(words):\n",
    "    return NGramModel(words, 1)\n",
    "models = list(map(f, data[:4]))\n",
    "print(\"Created %i models\" % len(models))\n",
    "\n",
    "\n",
    "for d, m in zip(data, models):\n",
    "    print(d, \"\\t\", m)\n",
    "\n",
    "austen_raw_text = gutenberg.raw(['austen-emma.txt', 'austen-persuasion.txt', 'austen-sense.txt']).lower()\n",
    "print(austen_raw_text[:800])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The preprocesses the text data and creates a unigram model. This model will be used for frequence analysis later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing these characters: {\"'\", '&', '_', '?', '4', '>', '5', '(', ';', '*', '9', ',', '3', '\\n', '2', '-', '7', ':', '[', '\"', '1', '!', '0', '.', '8', '6', '`', ']', ')'}\n",
      "1-gram model with 27 unique keys\n",
      "2-gram model with 600 unique keys\n"
     ]
    }
   ],
   "source": [
    "def generate_alphabet(alpha, omega):\n",
    "    \"\"\"Set of the english alphabet\"\"\"\n",
    "    return set([chr(i) for i in range(ord(alpha), ord(omega)+1)]) \n",
    "\n",
    "alphabet = generate_alphabet('a', 'z') # Set of the english alphabet\n",
    "\n",
    "strip = set(austen_raw_text).difference(alphabet)\n",
    "strip.difference_update(set([' ']))\n",
    "for s in strip:\n",
    "    austen_raw_text = austen_raw_text.replace(s, \"\")\n",
    "\n",
    "from ngram import character_tokenizer\n",
    "unigram_model = NGramModel(character_tokenizer(austen_raw_text), 1)\n",
    "bigram_model = NGramModel(character_tokenizer(austen_raw_text), 2)\n",
    "\n",
    "print(\"Removing these characters:\", strip)\n",
    "print(unigram_model)\n",
    "print(bigram_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The set of all english words in the corpus will also come in handy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7312 english words\n"
     ]
    }
   ],
   "source": [
    "engligh_words = set()\n",
    "for m in models[:1]:\n",
    "    engligh_words.update(set([k[0].lower() for k in list(m.keys()) if len(k[0])>=2]))\n",
    "    \n",
    "print(\"Found %i english words\" % len(engligh_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now find the most common characters in this english text and their probabilities (from relative frequencies)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(' ',) - 0.17508\n",
      "('e',) - 0.10457\n",
      "('t',) - 0.07146\n",
      "('a',) - 0.06508\n",
      "('o',) - 0.06436\n",
      "('n',) - 0.05892\n",
      "('i',) - 0.05631\n",
      "('h',) - 0.05141\n",
      "('s',) - 0.05130\n",
      "('r',) - 0.05015\n",
      "('d',) - 0.03463\n",
      "('l',) - 0.03331\n",
      "('u',) - 0.02380\n",
      "('m',) - 0.02354\n",
      "('w',) - 0.01977\n",
      "('c',) - 0.01941\n",
      "('f',) - 0.01858\n",
      "('y',) - 0.01830\n",
      "('g',) - 0.01596\n",
      "('b',) - 0.01298\n",
      "('p',) - 0.01274\n",
      "('v',) - 0.00927\n",
      "('k',) - 0.00509\n",
      "('x',) - 0.00144\n",
      "('j',) - 0.00126\n",
      "('q',) - 0.00106\n",
      "('z',) - 0.00020\n"
     ]
    }
   ],
   "source": [
    "from ngram import ordered_ngrams\n",
    "for unigram, prob in list(ordered_ngrams(unigram_model)):\n",
    "    print(\"%s - %.5f\" % (unigram, prob))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Caesar substitution crypto\n",
    "Maybe the most basic substitution crypto, based on charcter rotations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KZZAHXAZK\n"
     ]
    }
   ],
   "source": [
    "#alphabet = [chr(i) for i in range(ord('a'), ord('z')+1)]\n",
    "def caesar_encryption(word, offset=3):\n",
    "    enc = [chr(ord(char)+offset-len(alphabet)) if (ord(char)+offset)>ord('z') else chr(ord(char)+offset)\n",
    "           for char in word.lower() if char in alphabet]\n",
    "    return \"\".join(enc).upper()\n",
    "\n",
    "import random\n",
    "offset = random.randint(1, len(alphabet)-1)\n",
    "\n",
    "print(caesar_encryption(\"Et tu brute\", offset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now for finding the key to an unknown cryptogram (assuming it's a caesar crypto)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "message_to_alesia = \"YHUFLQJHWRULABRXUPRWKHUZDVDKDPVWHUDQGBRXUIDWKHUVPHOOVRIHOGHUEHUULHV\"\n",
    "n_key = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('H',) - 0.14925\n",
      "('U',) - 0.14925\n",
      "('V',) - 0.07463\n",
      "('D',) - 0.07463\n",
      "('R',) - 0.07463\n",
      "('W',) - 0.05970\n",
      "('L',) - 0.04478\n",
      "('K',) - 0.04478\n",
      "('P',) - 0.04478\n",
      "('O',) - 0.04478\n",
      "('B',) - 0.02985\n",
      "('I',) - 0.02985\n",
      "('G',) - 0.02985\n",
      "('X',) - 0.02985\n",
      "('Q',) - 0.02985\n",
      "('F',) - 0.01493\n",
      "('E',) - 0.01493\n",
      "('J',) - 0.01493\n",
      "('A',) - 0.01493\n",
      "('Z',) - 0.01493\n",
      "('Y',) - 0.01493\n"
     ]
    }
   ],
   "source": [
    "caesar_model = NGramModel(character_tokenizer(message_to_alesia), 1)\n",
    "for unigram, prob in list(ordered_ngrams(caesar_model)):\n",
    "    print(\"%s - %.5f\" % (unigram, prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oxkvbgzxmhkbqrhnkfhmaxkptltatflmxktgwrhnkytmaxklfxeelhyxewxkuxkkbxl\n"
     ]
    }
   ],
   "source": [
    "def caesar_decode(text, offset):\n",
    "    ret = str()\n",
    "    for i in range(len(text)):\n",
    "        c = ord(text[i]) - offset\n",
    "        if c > ord('Z'):\n",
    "            c -= len(alphabet)\n",
    "        if c < ord('A'):\n",
    "            c += len(alphabet)\n",
    "        ret += chr(c)\n",
    "    return ret\n",
    "\n",
    "message_from_caesar = caesar_decode(message_to_alesia, n_key)\n",
    "print(message_from_caesar.capitalize())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Something we can do to solve this, but the roman could not, was let a computer brute force this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 xgtekpigvqtkzaqwtoqvjgtycucjcouvgtcpfaqwthcvjgtuognnuqhgnfgtdgttkgu\n",
      "2 wfsdjohfupsjyzpvsnpuifsxbtbibntufsboezpvsgbuifstnfmmtpgfmefscfssjft\n",
      "3 vercingetorixyourmotherwasahamsterandyourfathersmellsofelderberries\n",
      "4 udqbhmfdsnqhwxntqlnsgdqvzrzgzlrsdqzmcxntqezsgdqrldkkrnedkcdqadqqhdr\n",
      "5 tcpaglecrmpgvwmspkmrfcpuyqyfykqrcpylbwmspdyrfcpqkcjjqmdcjbcpzcppgcq\n",
      "6 sbozfkdbqlofuvlrojlqebotxpxexjpqboxkavlrocxqebopjbiiplcbiaboyboofbp\n",
      "7 ranyejcapknetukqnikpdanswowdwiopanwjzukqnbwpdanoiahhokbahzanxanneao\n",
      "8 qzmxdibzojmdstjpmhjoczmrvnvcvhnozmviytjpmavoczmnhzggnjazgyzmwzmmdzn\n",
      "9 pylwchaynilcrsiolginbylqumubugmnyluhxsiolzunbylmgyffmizyfxylvyllcym\n",
      "10 oxkvbgzxmhkbqrhnkfhmaxkptltatflmxktgwrhnkytmaxklfxeelhyxewxkuxkkbxl\n",
      "11 nwjuafywlgjapqgmjeglzwjoskszseklwjsfvqgmjxslzwjkewddkgxwdvwjtwjjawk\n",
      "12 mvitzexvkfizopflidfkyvinrjryrdjkvireupfliwrkyvijdvccjfwvcuvisviizvj\n",
      "13 luhsydwujehynoekhcejxuhmqiqxqcijuhqdtoekhvqjxuhicubbievubtuhruhhyui\n",
      "14 ktgrxcvtidgxmndjgbdiwtglphpwpbhitgpcsndjgupiwtghbtaahdutastgqtggxth\n",
      "15 jsfqwbushcfwlmcifachvsfkogovoaghsfobrmciftohvsfgaszzgctszrsfpsffwsg\n",
      "16 irepvatrgbevklbhezbgurejnfnunzfgrenaqlbhesngurefzryyfbsryqreoreevrf\n",
      "17 hqdouzsqfadujkagdyaftqdimemtmyefqdmzpkagdrmftqdeyqxxearqxpqdnqdduqe\n",
      "18 gpcntyrpezctijzfcxzespchldlslxdepclyojzfcqlespcdxpwwdzqpwopcmpcctpd\n",
      "19 fobmsxqodybshiyebwydrobgkckrkwcdobkxniyebpkdrobcwovvcypovnoblobbsoc\n",
      "20 enalrwpncxarghxdavxcqnafjbjqjvbcnajwmhxdaojcqnabvnuubxonumnaknaarnb\n",
      "21 dmzkqvombwzqfgwczuwbpmzeiaipiuabmzivlgwcznibpmzaumttawnmtlmzjmzzqma\n",
      "22 clyjpunlavypefvbytvaolydhzhohtzalyhukfvbymhaolyztlsszvmlsklyilyyplz\n",
      "23 bkxiotmkzuxodeuaxsuznkxcgygngsyzkxgtjeuaxlgznkxyskrryulkrjkxhkxxoky\n",
      "24 ajwhnsljytwncdtzwrtymjwbfxfmfrxyjwfsidtzwkfymjwxrjqqxtkjqijwgjwwnjx\n",
      "25 zivgmrkixsvmbcsyvqsxlivaeweleqwxiverhcsyvjexlivwqippwsjiphivfivvmiw\n"
     ]
    }
   ],
   "source": [
    "for n in range(1, len(alphabet)):\n",
    "    print(n, caesar_decode(message_to_alesia, n).lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-to-one substitution crypto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BH8LCXLH0CXLH9YXEWQ8Y9CX9UYLXJWQUCXZ9WZF9X38FF9JXEWQ8Y9CXLH97XGWXLH9XHWUC9X0LXC87CXEWQ8YCXGWXHWQ9\n"
     ]
    }
   ],
   "source": [
    "intercepted_in_jerusalem = \"\"\"GPMCPIMEHMIRJXDCRMIRPMDH1PJCJXDH1MRP7IEHCMT4TIPLMRPJPMDQMIRJXDCRMIXMIRPML7EHM7D1EPH2PM2R7LWPJMRPJPM7H1MQE07IPTMGESPTMWP1JXXLMETMRPJPMR7KEHCMCJ7WWP1MRETMGESPMGPMEHSXJLMQE07IPMIR7IMTRPMETMEHMXDJM2DTIX14M7H1MSXJIRGEIRMETTDPMXDJM1PL7H1TMIRP4KPMW0P1MDTMGREIPMIRPMW7TI7J1TMIRP4KPMI75PHMPKPJ4IREHCMGPMR71MHXIMBDTIMSJXLMDTMSJXLMXDJMS7IRPJTM7H1MSJXLMXDJMS7IRPJTMS7IRPJT\"\"\"\n",
    "\n",
    "text = \"\"\"Whats this then Romanes eunt domus People called Romanes they go the house It says Romans go home\"\"\"\n",
    "#def encrypt_substitution(text):\n",
    "text = text.lower()\n",
    "unenc = list(set(text))\n",
    "symbols = [c.upper() for c in alphabet]\n",
    "symbols.extend(list(\"0123456789\"))\n",
    "s = list(symbols)\n",
    "random.shuffle(s)\n",
    "enc = s[:len(unenc)]\n",
    "\n",
    "key = dict()\n",
    "for a, b in zip(unenc, enc):\n",
    "    key[a] = b\n",
    "\n",
    "def substitute(text, encryption_key, replace=\"-\"):\n",
    "    ret = str()\n",
    "    for c in text:\n",
    "        if c in encryption_key.keys():\n",
    "            ret += encryption_key[c]\n",
    "        else:\n",
    "            if replace is not None:\n",
    "                ret += replace\n",
    "            else:\n",
    "                ret += c\n",
    "    return ret\n",
    "\n",
    "enc_text = substitute(text, key)\n",
    "print(enc_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'s': 'C',\n",
       " 'm': 'Q',\n",
       " 'p': 'Z',\n",
       " 'u': 'U',\n",
       " 'c': '3',\n",
       " 't': 'L',\n",
       " 'w': 'B',\n",
       " 'h': 'H',\n",
       " 'n': 'Y',\n",
       " ' ': 'X',\n",
       " 'r': 'E',\n",
       " 'l': 'F',\n",
       " 'y': '7',\n",
       " 'o': 'W',\n",
       " 'e': '9',\n",
       " 'i': '0',\n",
       " 'g': 'G',\n",
       " 'd': 'J',\n",
       " 'a': '8'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 's',\n",
       " 'Q': 'm',\n",
       " 'Z': 'p',\n",
       " 'U': 'u',\n",
       " '3': 'c',\n",
       " 'L': 't',\n",
       " 'B': 'w',\n",
       " 'H': 'h',\n",
       " 'Y': 'n',\n",
       " 'X': ' ',\n",
       " 'E': 'r',\n",
       " 'F': 'l',\n",
       " '7': 'y',\n",
       " 'W': 'o',\n",
       " '9': 'e',\n",
       " '0': 'i',\n",
       " 'G': 'g',\n",
       " 'J': 'd',\n",
       " '8': 'a'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reverse_key = dict()\n",
    "for a, b in [(k, key[k]) for k in key.keys()]:\n",
    "    reverse_key[b] = a\n",
    "reverse_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "whats this then romanes eunt domus people called romanes they go the house it says romans go home\n"
     ]
    }
   ],
   "source": [
    "print(substitute(enc_text, reverse_key))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(' ',) - 0.17508\n",
      "('e',) - 0.10457\n",
      "('t',) - 0.07146\n",
      "('a',) - 0.06508\n",
      "('o',) - 0.06436\n",
      "('n',) - 0.05892\n",
      "('i',) - 0.05631\n",
      "('h',) - 0.05141\n",
      "('s',) - 0.05130\n",
      "('r',) - 0.05015\n",
      "('d',) - 0.03463\n",
      "('l',) - 0.03331\n",
      "('u',) - 0.02380\n",
      "('m',) - 0.02354\n",
      "('w',) - 0.01977\n"
     ]
    }
   ],
   "source": [
    "from ngram import ordered_ngrams\n",
    "for unigram, prob in list(ordered_ngrams(unigram_model))[:15]:\n",
    "    print(\"%s - %.5f\" % (unigram, prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('M',) - 0.17500\n",
      "('P',) - 0.11111\n",
      "('I',) - 0.07500\n",
      "('R',) - 0.07222\n",
      "('J',) - 0.06667\n",
      "('T',) - 0.05556\n",
      "('7',) - 0.05556\n",
      "('E',) - 0.05000\n",
      "('X',) - 0.04722\n",
      "('H',) - 0.04444\n",
      "('D',) - 0.04167\n",
      "('1',) - 0.03889\n",
      "('S',) - 0.02778\n",
      "('L',) - 0.02500\n",
      "('C',) - 0.02222\n"
     ]
    }
   ],
   "source": [
    "m1 = NGramModel(character_tokenizer(intercepted_in_jerusalem), 1)\n",
    "for unigram, prob in list(ordered_ngrams(m1))[:15]:\n",
    "    print(\"%s - %.5f\" % (unigram, prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPMCPIMEHMIRJXDCRMIRPMDH1PJCJXDH1MRP7IEHCMT4TIPLMRPJPMDQMIRJXDCRMIXMIRPML7EHM7D1EPH2PM2R7LWPJMRPJPM7H1MQE07IPTMGESPTMWP1JXXLMETMRPJPMR7KEHCMCJ7WWP1MRETMGESPMGPMEHSXJLMQE07IPMIR7IMTRPMETMEHMXDJM2DTIX14M7H1MSXJIRGEIRMETTDPMXDJM1PL7H1TMIRP4KPMW0P1MDTMGREIPMIRPMW7TI7J1TMIRP4KPMI75PHMPKPJ4IREHCMGPMR71MHXIMBDTIMSJXLMDTMSJXLMXDJMS7IRPJTM7H1MSJXLMXDJMS7IRPJTMS7IRPJT\n"
     ]
    }
   ],
   "source": [
    "#key = {'': ''}\n",
    "\n",
    "#m1_sorted_keys = [k[0][0] for k in ordered_ngrams(m1)]\n",
    "#unigram_sorted_keys = [k[0][0] for k in ordered_ngrams(unigram_model)]\n",
    "#for enc, ref in list(zip(m1_sorted_keys[:5], unigram_sorted_keys[:5])):\n",
    "#    print(enc, ref)\n",
    "#    key[enc] = ref\n",
    "print(substitute(intercepted_in_jerusalem, key, replace=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('P', 'M') - 0.04735\n",
      "('I', 'R') - 0.03900\n",
      "('R', 'P') - 0.03621\n",
      "('T', 'M') - 0.03064\n",
      "('M', 'I') - 0.02786\n",
      "('P', 'J') - 0.02507\n",
      "('E', 'H') - 0.01950\n",
      "('M', 'R') - 0.01950\n",
      "('J', 'X') - 0.01950\n",
      "('X', 'D') - 0.01950\n"
     ]
    }
   ],
   "source": [
    "m2 = NGramModel(character_tokenizer(intercepted_in_jerusalem), 2)\n",
    "for unigram, prob in list(ordered_ngrams(m2))[:10]:\n",
    "    print(\"%s - %.5f\" % (unigram, prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('e', ' ') - 0.03101\n",
      "('h', 'e') - 0.02211\n",
      "(' ', 't') - 0.02183\n",
      "('t', 'h') - 0.02001\n",
      "('d', ' ') - 0.01981\n",
      "('t', ' ') - 0.01905\n",
      "(' ', 'a') - 0.01876\n",
      "('e', 'r') - 0.01679\n",
      "('s', ' ') - 0.01675\n",
      "('i', 'n') - 0.01549\n"
     ]
    }
   ],
   "source": [
    "from ngram import ordered_ngrams\n",
    "for bigram, prob in list(ordered_ngrams(bigram_model))[:10]:\n",
    "    print(\"%s - %.5f\" % (bigram, prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17 words found\n",
      "['any', 'age', 'ate', 'ask', 'are', 'arm', 'air', 'and', 'all', 'add', 'apt', 'ago', 'aid', 'awe', 'act', 'aye', 'art']\n"
     ]
    }
   ],
   "source": [
    "result = list()\n",
    "for w in engligh_words:\n",
    "    if len(w) == 3 and w[0]=='a':\n",
    "        result.append(w)\n",
    "print(len(result), \"words found\")\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
