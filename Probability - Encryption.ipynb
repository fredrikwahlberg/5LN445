{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some examples of early encryption\n",
    "First, we need some reference data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating a spark session...done\n",
      "[nltk_data] Error loading gutenberg: <urlopen error [Errno -3]\n",
      "[nltk_data]     Temporary failure in name resolution>\n",
      "Available books: ['austen-emma.txt', 'austen-persuasion.txt', 'austen-sense.txt', 'bible-kjv.txt', 'blake-poems.txt', 'bryant-stories.txt', 'burgess-busterbrown.txt', 'carroll-alice.txt', 'chesterton-ball.txt', 'chesterton-brown.txt', 'chesterton-thursday.txt', 'edgeworth-parents.txt', 'melville-moby_dick.txt', 'milton-paradise.txt', 'shakespeare-caesar.txt', 'shakespeare-hamlet.txt', 'shakespeare-macbeth.txt', 'whitman-leaves.txt']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import gutenberg\n",
    "from ngram import NGramModel\n",
    "import numpy as np\n",
    "\n",
    "print(\"Creating a spark session...\", end=\"\")\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession\\\n",
    "        .builder\\\n",
    "        .appName(\"asdf\")\\\n",
    "        .getOrCreate()\n",
    "print(\"done\")\n",
    "\n",
    "nltk.download('gutenberg')\n",
    "\n",
    "print(\"Available books:\", gutenberg.fileids())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 3 models\n",
      "['[', 'Emma', 'by', 'Jane', 'Austen', '1816', ']', ...] \t 1-gram model with 7811 unique keys\n",
      "['[', 'Persuasion', 'by', 'Jane', 'Austen', '1818', ...] \t 1-gram model with 6132 unique keys\n",
      "['[', 'Sense', 'and', 'Sensibility', 'by', 'Jane', ...] \t 1-gram model with 6833 unique keys\n"
     ]
    }
   ],
   "source": [
    "fileids = spark.sparkContext.parallelize(gutenberg.fileids()[:3])\n",
    "\n",
    "def make_unigram_models(fileid):\n",
    "    from nltk.corpus import gutenberg\n",
    "    return NGramModel(gutenberg.words(fileid), 1)\n",
    "models = fileids.map(make_unigram_models).collect()\n",
    "\n",
    "print(\"Created %i models\" % len(models))\n",
    "\n",
    "for fid, m in zip(fileids.collect(), models):\n",
    "    print(gutenberg.words(fid), \"\\t\", m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The set of all english words in the corpus will also come in handy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 7079 english words so far\n",
      "We have 8824 english words so far\n",
      "We have 10294 english words so far\n"
     ]
    }
   ],
   "source": [
    "def word_isalpha(word):\n",
    "    for c in word:\n",
    "        if not c.isalpha():\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "english_words = set()\n",
    "for m in models:\n",
    "    words = [k[0].lower() for k in list(m.keys())]\n",
    "    english_words.update(set([w for w in words if word_isalpha(w)]))\n",
    "    print(\"We have %i english words so far\" % len(english_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['portsmouth', 'example', 'swinging', 'painfully', 'unnoticed', 'uniting', 'estate', 'parliaments', 'odd', 'bragge', 'piece', 'breeding', 'clapped', 'relinquishing', 'smells', 'imprisonment', 'disclaiming', 'prayer', 'happiness', 'demonstrations', 'preceded', 'ride', 'ox', 'scoundrel', 'betimes', 'confusedly', 'disfavour', 'inconsideration', 'gathered', 'zealously', 'gun', 'noise', 'navy', 'prodigiously', 'further', 'ask', 'concerto', 'combine', 'attending', 'frames', 'misunderstanding', 'verses', 'repack', 'hon', 'mama', 'introduces', 'nurses', 'fatiguing', 'stanhill', 'cannot', 'dark', 'endanger', 'founded', 'retreated', 'softener', 'success', 'merged', 'sort', 'quietly', 'bush', 'glibly', 'naval', 'orchestra', 'relating', 'implies', 'bushel', 'dim', 'petted', 'significant', 'outweighs', 'berkeley', 'serviceable', 'assembled', 'extinguished', 'impropriety', 'soldier', 'sea', 'syllables', 'order', 'fanciful', 'memorial', 'yourself', 'contrasted', 'abatement', 'constrained', 'art', 'repute', 'brunswick', 'ardent', 'bought', 'thrown', 'females', 'adviser', 'garden', 'eighth', 'bide', 'illustration', 'allayed', 'kensington', 'edtions']\n"
     ]
    }
   ],
   "source": [
    "from random import choices\n",
    "print(choices(list(english_words), k=100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's clean up some Austen books as trining data for character models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Emma by Jane Austen 1816]\n",
      "\n",
      "VOLUME I\n",
      "\n",
      "CHAPTER I\n",
      "\n",
      "\n",
      "Emma Woodhouse, handsome, clever, and rich, with a comfortable home\n",
      "and happy disposition, seemed to unite some of the best blessings\n",
      "of existence; and had lived nearly twenty-one years in the world\n",
      "with very little to distress or vex her.\n",
      "\n",
      "She was the youngest of the two daughters of a most affectionate,\n",
      "indulgent father; and had, in consequence of her sister's marriage,\n",
      "been mistress of his house from a very early period.  Her mother\n",
      "had died too long ago for her to have more than an indistinct\n",
      "remembrance of her caresses; and her place had b\n",
      "---\n",
      "emma by jane austen   volume i  chapter i   emma woodhouse handsome clever and rich with a comfortable home and happy disposition seemed to unite some of the best blessings of existence and had lived nearly twentyone years in the world with very little to distress or vex her  she was the youngest of the two daughters of a most affectionate indulgent father and had in consequence of her sisters marriage been mistress of his house from a very early period  her mother had died too long ago for her to have more than an indistinct remembrance of her caresses and her place had been supplied by an ex\n",
      "1948591 characters in training data\n"
     ]
    }
   ],
   "source": [
    "austen_text = [gutenberg.raw(fid) for fid in ['austen-emma.txt', 'austen-persuasion.txt', 'austen-sense.txt']]\n",
    "print(austen_text[0][:600])\n",
    "\n",
    "def generate_alphabet(alpha, omega):\n",
    "    \"\"\"Set of the english alphabet\"\"\"\n",
    "    return set([chr(i) for i in range(ord(alpha), ord(omega)+1)]) \n",
    "\n",
    "def clean_text(text, allowed):\n",
    "    ret = text.lower()\n",
    "    strip = set(ret).difference(allowed)\n",
    "    if \" \" in allowed:\n",
    "        for s in strip:\n",
    "            if s in ['\\n', '\\t']:\n",
    "                ret = ret.replace(s, \" \")\n",
    "            else:\n",
    "                ret = ret.replace(s, \"\")\n",
    "    else:\n",
    "        for s in strip:\n",
    "            ret = ret.replace(s, \"\")\n",
    "    return ret\n",
    "\n",
    "alphabet = generate_alphabet('a', 'z') # Set of the english alphabet\n",
    "allowed_characters = set([' '])\n",
    "allowed_characters.update(alphabet)\n",
    "for i in range(len(austen_text)):\n",
    "    austen_text[i] = clean_text(austen_text[i], allowed_characters)\n",
    "\n",
    "print(\"---\")\n",
    "print(austen_text[0][:600])\n",
    "print(\"%i characters in training data\" % np.sum([len(t) for t in austen_text]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the data cleaned, we are ready to create some character ngram models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-gram model with 27 unique keys\n",
      "2-gram model with 560 unique keys\n",
      "3-gram model with 5365 unique keys\n",
      "4-gram model with 24737 unique keys\n"
     ]
    }
   ],
   "source": [
    "spark_texts = spark.sparkContext.parallelize(austen_text)\n",
    "unigram_model = spark_texts.map(lambda data: NGramModel(list(data), 1)).reduce(lambda a, b: a.union(b))\n",
    "print(unigram_model)\n",
    "bigram_model = spark_texts.map(lambda data: NGramModel(list(data), 2)).reduce(lambda a, b: a.union(b))\n",
    "print(bigram_model)\n",
    "trigram_model = spark_texts.map(lambda data: NGramModel(list(data), 3)).reduce(lambda a, b: a.union(b))\n",
    "print(trigram_model)\n",
    "quadgram_model = spark_texts.map(lambda data: NGramModel(list(data), 4)).reduce(lambda a, b: a.union(b))\n",
    "print(quadgram_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unigram: o towumciiyhooetl  ptnrlo  os oioht  esbmtse  aaacnnaep ir  nddehrafr rni d  r efk r ueeoa\n",
      "\n",
      "bigram: hid cofino we sh m thad ave coomumy had then sthes it foung bol by t ad bme d me w   st ju\n",
      "\n",
      "trigram:  inexprushe dou walf thend it worddess ort ingairced his of hicas spenes be to cal be day \n",
      "\n",
      "quadgram: emma dass bod but thearthe alk was of unat  ne el lind   the explad evoin prod elf ling se\n"
     ]
    }
   ],
   "source": [
    "print(\"unigram:\", \"\".join(unigram_model.predict_sequence(90)))\n",
    "print()\n",
    "print(\"bigram:\", \"\".join(bigram_model.predict_sequence(90)))\n",
    "print()\n",
    "print(\"trigram:\", \"\".join(trigram_model.predict_sequence(90)))\n",
    "print()\n",
    "print(\"quadgram:\", \"\".join(trigram_model.predict_sequence(90)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now find the most common characters in this english text and their probabilities (from relative frequencies)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(' ',) - 0.19206\n",
      "('e',) - 0.10242\n",
      "('t',) - 0.06999\n",
      "('a',) - 0.06374\n",
      "('o',) - 0.06304\n",
      "('n',) - 0.05771\n",
      "('i',) - 0.05516\n",
      "('h',) - 0.05035\n",
      "('s',) - 0.05025\n",
      "('r',) - 0.04912\n",
      "('d',) - 0.03392\n",
      "('l',) - 0.03262\n",
      "('u',) - 0.02331\n",
      "('m',) - 0.02306\n",
      "('w',) - 0.01936\n",
      "('c',) - 0.01901\n",
      "('f',) - 0.01820\n",
      "('y',) - 0.01793\n",
      "('g',) - 0.01563\n",
      "('b',) - 0.01272\n",
      "('p',) - 0.01248\n",
      "('v',) - 0.00908\n",
      "('k',) - 0.00498\n",
      "('x',) - 0.00141\n",
      "('j',) - 0.00124\n",
      "('q',) - 0.00103\n",
      "('z',) - 0.00020\n"
     ]
    }
   ],
   "source": [
    "from ngram import ordered_ngrams\n",
    "for unigram, prob in list(ordered_ngrams(unigram_model)):\n",
    "    print(\"%s - %.5f\" % (unigram, prob))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Caesar substitution crypto\n",
    "Maybe the most basic substitution crypto, based on charcter rotations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UJJKRHKJU\n"
     ]
    }
   ],
   "source": [
    "def caesar_encryption(word, offset=3):\n",
    "    enc = [chr(ord(char)+offset-len(alphabet)) if (ord(char)+offset)>ord('z') else chr(ord(char)+offset)\n",
    "           for char in word.lower() if char in alphabet]\n",
    "    return \"\".join(enc).upper()\n",
    "\n",
    "import random\n",
    "offset = random.randint(1, len(alphabet)-1)\n",
    "\n",
    "print(caesar_encryption(\"Et tu brute\", offset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now for finding the key to an unknown cryptogram (assuming it's a caesar crypto)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "message_to_alesia = \"YHUFLQJHWRULABRXUPRWKHUZDVDKDPVWHUDQGBRXUIDWKHUVPHOOVRIHOGHUEHUULHV\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('H',) - 0.14925\n",
      "('U',) - 0.14925\n",
      "('V',) - 0.07463\n",
      "('D',) - 0.07463\n",
      "('R',) - 0.07463\n",
      "('W',) - 0.05970\n",
      "('L',) - 0.04478\n",
      "('K',) - 0.04478\n",
      "('P',) - 0.04478\n",
      "('O',) - 0.04478\n",
      "('B',) - 0.02985\n",
      "('I',) - 0.02985\n",
      "('G',) - 0.02985\n",
      "('X',) - 0.02985\n",
      "('Q',) - 0.02985\n",
      "('F',) - 0.01493\n",
      "('E',) - 0.01493\n",
      "('J',) - 0.01493\n",
      "('A',) - 0.01493\n",
      "('Z',) - 0.01493\n",
      "('Y',) - 0.01493\n"
     ]
    }
   ],
   "source": [
    "caesar_model = NGramModel(list(message_to_alesia), 1)\n",
    "for unigram, prob in list(ordered_ngrams(caesar_model)):\n",
    "    print(\"%s - %.5f\" % (unigram, prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def caesar_decode(text, offset):\n",
    "    ret = str()\n",
    "    for i in range(len(text)):\n",
    "        c = ord(text[i]) - offset\n",
    "        if c > ord('Z'):\n",
    "            c -= len(alphabet)\n",
    "        if c < ord('A'):\n",
    "            c += len(alphabet)\n",
    "        ret += chr(c)\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vercingetorixyourmotherwasahamsterandyourfathersmellsofelderberries\n"
     ]
    }
   ],
   "source": [
    "n_key = 3\n",
    "message_from_caesar = caesar_decode(message_to_alesia, n_key)\n",
    "print(message_from_caesar.capitalize())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Something we can do to solve this, but the roman could not, was let a computer brute force this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 xgtekpigvqtkzaqwtoqvjgtycucjcouvgtcpfaqwthcvjgtuognnuqhgnfgtdgttkgu\n",
      "2 wfsdjohfupsjyzpvsnpuifsxbtbibntufsboezpvsgbuifstnfmmtpgfmefscfssjft\n",
      "3 vercingetorixyourmotherwasahamsterandyourfathersmellsofelderberries\n",
      "4 udqbhmfdsnqhwxntqlnsgdqvzrzgzlrsdqzmcxntqezsgdqrldkkrnedkcdqadqqhdr\n",
      "5 tcpaglecrmpgvwmspkmrfcpuyqyfykqrcpylbwmspdyrfcpqkcjjqmdcjbcpzcppgcq\n",
      "6 sbozfkdbqlofuvlrojlqebotxpxexjpqboxkavlrocxqebopjbiiplcbiaboyboofbp\n",
      "7 ranyejcapknetukqnikpdanswowdwiopanwjzukqnbwpdanoiahhokbahzanxanneao\n",
      "8 qzmxdibzojmdstjpmhjoczmrvnvcvhnozmviytjpmavoczmnhzggnjazgyzmwzmmdzn\n",
      "9 pylwchaynilcrsiolginbylqumubugmnyluhxsiolzunbylmgyffmizyfxylvyllcym\n",
      "10 oxkvbgzxmhkbqrhnkfhmaxkptltatflmxktgwrhnkytmaxklfxeelhyxewxkuxkkbxl\n",
      "11 nwjuafywlgjapqgmjeglzwjoskszseklwjsfvqgmjxslzwjkewddkgxwdvwjtwjjawk\n",
      "12 mvitzexvkfizopflidfkyvinrjryrdjkvireupfliwrkyvijdvccjfwvcuvisviizvj\n",
      "13 luhsydwujehynoekhcejxuhmqiqxqcijuhqdtoekhvqjxuhicubbievubtuhruhhyui\n",
      "14 ktgrxcvtidgxmndjgbdiwtglphpwpbhitgpcsndjgupiwtghbtaahdutastgqtggxth\n",
      "15 jsfqwbushcfwlmcifachvsfkogovoaghsfobrmciftohvsfgaszzgctszrsfpsffwsg\n",
      "16 irepvatrgbevklbhezbgurejnfnunzfgrenaqlbhesngurefzryyfbsryqreoreevrf\n",
      "17 hqdouzsqfadujkagdyaftqdimemtmyefqdmzpkagdrmftqdeyqxxearqxpqdnqdduqe\n",
      "18 gpcntyrpezctijzfcxzespchldlslxdepclyojzfcqlespcdxpwwdzqpwopcmpcctpd\n",
      "19 fobmsxqodybshiyebwydrobgkckrkwcdobkxniyebpkdrobcwovvcypovnoblobbsoc\n",
      "20 enalrwpncxarghxdavxcqnafjbjqjvbcnajwmhxdaojcqnabvnuubxonumnaknaarnb\n",
      "21 dmzkqvombwzqfgwczuwbpmzeiaipiuabmzivlgwcznibpmzaumttawnmtlmzjmzzqma\n",
      "22 clyjpunlavypefvbytvaolydhzhohtzalyhukfvbymhaolyztlsszvmlsklyilyyplz\n",
      "23 bkxiotmkzuxodeuaxsuznkxcgygngsyzkxgtjeuaxlgznkxyskrryulkrjkxhkxxoky\n",
      "24 ajwhnsljytwncdtzwrtymjwbfxfmfrxyjwfsidtzwkfymjwxrjqqxtkjqijwgjwwnjx\n",
      "25 zivgmrkixsvmbcsyvqsxlivaeweleqwxiverhcsyvjexlivwqippwsjiphivfivvmiw\n"
     ]
    }
   ],
   "source": [
    "for n in range(1, len(alphabet)):\n",
    "    print(n, caesar_decode(message_to_alesia, n).lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-to-one substitution crypto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AHY2832HZ832HSK3LOFYKS83STK23IOFT835SO5NS37YNNSI3LOFYKS832HSW30O32HS3HOT8S3Z238YW83LOFYK830O3HOFS\n"
     ]
    }
   ],
   "source": [
    "text = \"\"\"Whats this then Romanes eunt domus People called Romanes they go the house It says Romans go home\"\"\"\n",
    "#def encrypt_substitution(text):\n",
    "text = text.lower()\n",
    "unenc = list(set(text))\n",
    "symbols = [c.upper() for c in alphabet]\n",
    "symbols.extend(list(\"0123456789\"))\n",
    "s = list(symbols)\n",
    "random.shuffle(s)\n",
    "enc = s[:len(unenc)]\n",
    "\n",
    "key = dict()\n",
    "for a, b in zip(unenc, enc):\n",
    "    key[a] = b\n",
    "\n",
    "def substitute(text, encryption_key, replace=\"-\"):\n",
    "    ret = str()\n",
    "    for c in text:\n",
    "        if c in encryption_key.keys():\n",
    "            ret += encryption_key[c]\n",
    "        else:\n",
    "            if replace is not None:\n",
    "                ret += replace\n",
    "            else:\n",
    "                ret += c\n",
    "    return ret\n",
    "\n",
    "enc_text = substitute(text, key)\n",
    "print(enc_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{' ': '3',\n",
       " 'a': 'Y',\n",
       " 'c': '7',\n",
       " 'd': 'I',\n",
       " 'e': 'S',\n",
       " 'g': '0',\n",
       " 'h': 'H',\n",
       " 'i': 'Z',\n",
       " 'l': 'N',\n",
       " 'm': 'F',\n",
       " 'n': 'K',\n",
       " 'o': 'O',\n",
       " 'p': '5',\n",
       " 'r': 'L',\n",
       " 's': '8',\n",
       " 't': '2',\n",
       " 'u': 'T',\n",
       " 'w': 'A',\n",
       " 'y': 'W'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0': 'g',\n",
       " '2': 't',\n",
       " '3': ' ',\n",
       " '5': 'p',\n",
       " '7': 'c',\n",
       " '8': 's',\n",
       " 'A': 'w',\n",
       " 'F': 'm',\n",
       " 'H': 'h',\n",
       " 'I': 'd',\n",
       " 'K': 'n',\n",
       " 'L': 'r',\n",
       " 'N': 'l',\n",
       " 'O': 'o',\n",
       " 'S': 'e',\n",
       " 'T': 'u',\n",
       " 'W': 'y',\n",
       " 'Y': 'a',\n",
       " 'Z': 'i'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reverse_key = dict()\n",
    "for a, b in [(k, key[k]) for k in key.keys()]:\n",
    "    reverse_key[b] = a\n",
    "reverse_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "whats this then romanes eunt domus people called romanes they go the house it says romans go home\n"
     ]
    }
   ],
   "source": [
    "print(substitute(enc_text, reverse_key))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "intercepted_in_jerusalem = \"\"\"GPMCPIMEHMIRJXDCRMIRPMDH1PJCJXDH1MRP7IEHCMT4TIPLMRPJPMDQMIRJXDCRMIXMIRPML7EHM7D1EPH2PM2R7LWPJMRPJPM7H1MQE07IPTMGESPTMWP1JXXLMETMRPJPMR7KEHCMCJ7WWP1MRETMGESPMGPMEHSXJLMQE07IPMIR7IMTRPMETMEHMXDJM2DTIX14M7H1MSXJIRGEIRMETTDPMXDJM1PL7H1TMIRP4KPMW0P1MDTMGREIPMIRPMW7TI7J1TMIRP4KPMI75PHMPKPJ4IREHCMGPMR71MHXIMBDTIMSJXLMDTMSJXLMXDJMS7IRPJTM7H1MSJXLMXDJMS7IRPJTMS7IRPJT\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(' ',) - 0.19206\n",
      "('e',) - 0.10242\n",
      "('t',) - 0.06999\n",
      "('a',) - 0.06374\n",
      "('o',) - 0.06304\n",
      "('n',) - 0.05771\n",
      "('i',) - 0.05516\n",
      "('h',) - 0.05035\n",
      "('s',) - 0.05025\n",
      "('r',) - 0.04912\n"
     ]
    }
   ],
   "source": [
    "from ngram import ordered_ngrams\n",
    "for unigram, prob in list(ordered_ngrams(unigram_model))[:10]:\n",
    "    print(\"%s - %.5f\" % (unigram, prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('M',) - 0.17500\n",
      "('P',) - 0.11111\n",
      "('I',) - 0.07500\n",
      "('R',) - 0.07222\n",
      "('J',) - 0.06667\n",
      "('T',) - 0.05556\n",
      "('7',) - 0.05556\n",
      "('E',) - 0.05000\n",
      "('X',) - 0.04722\n",
      "('H',) - 0.04444\n"
     ]
    }
   ],
   "source": [
    "m1 = NGramModel(list(intercepted_in_jerusalem), 1)\n",
    "for unigram, prob in list(ordered_ngrams(m1))[:10]:\n",
    "    print(\"%s - %.5f\" % (unigram, prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ge CeI EH IRJXDCR IRe DH1eJCJXDH1 Re7IEHC T4TIeL ReJe DQ IRJXDCR IX IRe L7EH 7D1EeH2e 2R7LWeJ ReJe 7H1 QE07IeT GESeT We1JXXL ET ReJe R7KEHC CJ7WWe1 RET GESe Ge EHSXJL QE07Ie IR7I TRe ET EH XDJ 2DTIX14 7H1 SXJIRGEIR ETTDe XDJ 1eL7H1T IRe4Ke W0e1 DT GREIe IRe W7TI7J1T IRe4Ke I75eH eKeJ4IREHC Ge R71 HXI BDTI SJXL DT SJXL XDJ S7IReJT 7H1 SJXL XDJ S7IReJT S7IReJT\n"
     ]
    }
   ],
   "source": [
    "key = dict()\n",
    "key['M'] = ' '\n",
    "key['P'] = 'e'\n",
    "\n",
    "print(substitute(intercepted_in_jerusalem, key, replace=None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('P', 'M') - 0.04735\n",
      "('I', 'R') - 0.03900\n",
      "('R', 'P') - 0.03621\n",
      "('T', 'M') - 0.03064\n",
      "('M', 'I') - 0.02786\n",
      "('P', 'J') - 0.02507\n",
      "('E', 'H') - 0.01950\n",
      "('M', 'R') - 0.01950\n",
      "('J', 'X') - 0.01950\n",
      "('X', 'D') - 0.01950\n"
     ]
    }
   ],
   "source": [
    "m2 = NGramModel(list(intercepted_in_jerusalem), 2)\n",
    "for unigram, prob in list(ordered_ngrams(m2))[:10]:\n",
    "    print(\"%s - %.5f\" % (unigram, prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('e', ' ') - 0.03374\n",
      "(' ', 't') - 0.02382\n",
      "('h', 'e') - 0.02164\n",
      "('d', ' ') - 0.02139\n",
      "(' ', 'a') - 0.02104\n",
      "('t', ' ') - 0.02060\n",
      "('t', 'h') - 0.01946\n",
      "('s', ' ') - 0.01832\n",
      "('e', 'r') - 0.01641\n",
      "(' ', 'h') - 0.01599\n"
     ]
    }
   ],
   "source": [
    "from ngram import ordered_ngrams\n",
    "for bigram, prob in list(ordered_ngrams(bigram_model))[:10]:\n",
    "    print(\"%s - %.5f\" % (bigram, prob))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Match words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 words found\n",
      "['we', 've', 'ye', 're', 'be', 'se', 'me', 'de', 'he']\n"
     ]
    }
   ],
   "source": [
    "result = list()\n",
    "for w in english_words:\n",
    "    if len(w) == 2 and w[1]=='e':\n",
    "        result.append(w)\n",
    "print(len(result), \"words found\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MCMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it will be seen that this mere painstaking burrower and grubworm of a poor devil of a subsub appears to have g\n",
      "YZPSQ WKIFXTMDECLHGNOARUJBV\n",
      "lavdt ohpwkynzfxesrbugcqmji\n",
      "YZPSQ WKIFXTMDECLHGNOARUJBV\n"
     ]
    }
   ],
   "source": [
    "text = clean_text(gutenberg.raw('melville-moby_dick.txt'), allowed_characters)[:10000]\n",
    "n_show = text.find(\"it will be seen\")\n",
    "print(text[n_show:n_show+110])\n",
    "\n",
    "chars_in_text = set(text)\n",
    "chars = \"\".join([e for e in chars_in_text])\n",
    "symbols = list(chars.upper())\n",
    "random.shuffle(symbols)\n",
    "symbols = \"\".join(symbols)\n",
    "\n",
    "def substitute(text, symbols, chars):\n",
    "    ret = text\n",
    "    for i in range(len(chars)):\n",
    "        ret = ret.replace(symbols[i], chars[i])\n",
    "    return ret\n",
    "\n",
    "print(symbols)\n",
    "print(chars)\n",
    "print(substitute(symbols, chars, symbols))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
